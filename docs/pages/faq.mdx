---
title: FAQ
description: Common questions about design choices and reliability
---

# FAQ

## Why not just one LLM call and done?

Because real document extraction has malformed outputs, missing fields, and low confidence cases. Single call pipelines hide uncertainty and produce brittle automation.

## Why keep prompts in code constants?

Prompt versions become part of deployable behavior and code review. This makes changes traceable.

## Why persist raw model outputs?

For audit, debugging, and prompt tuning. Without this, post-incident analysis is guesswork.

## Does this replace human reviewers?

No. It reduces repetitive manual extraction and escalates uncertain cases to reviewers.

## Can this scale beyond payslips and invoices?

Yes. Add new schema structs, validation rules, and type detection logic, then extend the ladder if needed.

## Is this architecture vendor locked?

No. OpenAI client is behind an interface. You can replace implementation while keeping the workflow and validation system.
